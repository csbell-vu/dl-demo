{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edd7835",
   "metadata": {},
   "source": [
    "# dl-demo\n",
    "> A demonstration of low code, high impact applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2c9d8",
   "metadata": {},
   "source": [
    "First, we'll install the transformers pacakge from HuggingFace.  If you're not on Google Colab, don't worry about executing this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38262da",
   "metadata": {},
   "source": [
    "Let's get into our workflow.  First, we'll import the transformers and pipeline functionality which will give us access to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f069c-c029-4c25-87a9-1e81029e9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2fdbe",
   "metadata": {},
   "source": [
    "Let's instantiate our object detection transformers model and pass in the URL of the image of interest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0be33b-5140-4d71-bf0e-4a2374f92a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9440234899520874,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 102, 'ymin': 197, 'xmax': 177, 'ymax': 294}},\n",
       " {'score': 0.9432401061058044,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 193, 'ymin': 113, 'xmax': 211, 'ymax': 140}},\n",
       " {'score': 0.9678061604499817,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 149, 'ymin': 148, 'xmax': 179, 'ymax': 196}},\n",
       " {'score': 0.9873580932617188,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 176, 'ymin': 116, 'xmax': 189, 'ymax': 140}},\n",
       " {'score': 0.9671748280525208,\n",
       "  'label': 'couch',\n",
       "  'box': {'xmin': 372, 'ymin': 220, 'xmax': 440, 'ymax': 337}},\n",
       " {'score': 0.9940884113311768,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 174, 'ymin': 144, 'xmax': 213, 'ymax': 200}},\n",
       " {'score': 0.9357931613922119,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 188, 'ymin': 117, 'xmax': 200, 'ymax': 132}},\n",
       " {'score': 0.9207999110221863,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 249, 'ymin': 140, 'xmax': 283, 'ymax': 193}},\n",
       " {'score': 0.9967083930969238,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 224, 'ymin': 116, 'xmax': 242, 'ymax': 142}},\n",
       " {'score': 0.9539520740509033,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 18, 'ymin': 142, 'xmax': 44, 'ymax': 154}},\n",
       " {'score': 0.9116322994232178,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 2, 'ymin': 129, 'xmax': 153, 'ymax': 232}},\n",
       " {'score': 0.9609153866767883,\n",
       "  'label': 'dining table',\n",
       "  'box': {'xmin': 221, 'ymin': 147, 'xmax': 318, 'ymax': 201}},\n",
       " {'score': 0.9497563242912292,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 302, 'ymin': 149, 'xmax': 337, 'ymax': 203}},\n",
       " {'score': 0.9536303281784058,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 0, 'ymin': 176, 'xmax': 128, 'ymax': 299}},\n",
       " {'score': 0.9463343024253845,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 188, 'ymin': 116, 'xmax': 204, 'ymax': 140}},\n",
       " {'score': 0.9761590361595154,\n",
       "  'label': 'book',\n",
       "  'box': {'xmin': 447, 'ymin': 306, 'xmax': 567, 'ymax': 349}},\n",
       " {'score': 0.9761921167373657,\n",
       "  'label': 'person',\n",
       "  'box': {'xmin': 201, 'ymin': 112, 'xmax': 214, 'ymax': 137}},\n",
       " {'score': 0.9442009329795837,\n",
       "  'label': 'dining table',\n",
       "  'box': {'xmin': 222, 'ymin': 146, 'xmax': 318, 'ymax': 161}},\n",
       " {'score': 0.9964503049850464,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 266, 'ymin': 151, 'xmax': 308, 'ymax': 207}},\n",
       " {'score': 0.9366861581802368,\n",
       "  'label': 'chair',\n",
       "  'box': {'xmin': 253, 'ymin': 139, 'xmax': 279, 'ymax': 151}}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create object detection pipeline\n",
    "object_detection_model = pipeline('object-detection', device=0)\n",
    "\n",
    "#Perform object detection using instantiated model\n",
    "object_detection_model('https://engineering.vanderbilt.edu/solutions/images/wondery.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24830a79",
   "metadata": {},
   "source": [
    "Nice!  This returns the results for programmatic usage if desired!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
